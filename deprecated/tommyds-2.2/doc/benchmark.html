<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>TommyDS</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="tommy.css" rel="stylesheet" type="text/css">
</head>
<body>

<!-- Generated by Doxygen 1.7.3 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Tommy Benchmarks </h1>  </div>
</div>
<div class="contents">
<div class="textblock"><p>To evaluate Tommy performances, an extensive benchmark was done, comparing it to the best libraries of data structures available:</p>
<p>Specifically we test:</p>
<ul>
<li><a class="el" href="tommyhashtbl_8h.html#a506978bdee7fd24f76a0ba7547206513" title="Hashtable container type.">tommy_hashtable</a> - Fixed size chained hashtable.</li>
<li><a class="el" href="tommyhashdyn_8h.html#a00c8b944d273f38f9eef91417a1e8991" title="Hashtable container type.">tommy_hashdyn</a> - Dynamic chained hashtable.</li>
<li><a class="el" href="tommyhashlin_8h.html#ad910f88af8bcd013a8e3cd30d528b904" title="Hashtable container type.">tommy_hashlin</a> - Linear chained hashtable.</li>
<li><a class="el" href="tommytrie_8h.html#a05c17b0ace098768808aa9effcaa9559" title="Trie container type.">tommy_trie</a> - Trie optimized for cache usage.</li>
<li><a class="el" href="tommytrieinp_8h.html#aa375bb131f3d221a24774aef08b27a0a" title="Trie container type.">tommy_trie_inplace</a> - Trie completely inplace.</li>
<li><a href="http://www.canonware.com/rb/">rbtree</a> - Red-black tree by Jason Evans.</li>
<li><a href="http://www.nedprod.com/programs/portable/nedtries/">nedtrie</a> - Binary trie inplace by Niall Douglas.</li>
<li><a href="http://attractivechaos.awardspace.com/">khash</a> - Dynamic open addressing hashtable by Attractive Chaos.</li>
<li><a href="http://uthash.sourceforge.net/">uthash</a> - Dynamic chaining hashtable by Troy D. Hanson.</li>
<li><a href="http://judy.sourceforge.net/">judy</a> - Burst trie (JudyL) by Doug Baskins.</li>
<li><a href="http://code.google.com/p/judyarray/">judyarray</a> - Burst trie by Karl Malbrain.</li>
<li><a href="http://code.google.com/p/google-sparsehash/">googledensehash</a> - Dynamic open addressing hashtable by Craig Silverstein at Google.</li>
<li><a href="http://code.google.com/p/cpp-btree/">googlebtree</a> - Btree by Google.</li>
<li><a href="http://panthema.net/2007/stx-btree/">stxbtree</a> - STX Btree by Timo Bingmann.</li>
<li><a href="http://www.cplusplus.com/reference/unordered_map/unordered_map/">c++unordered_map</a> - C++ STL unordered_map&lt;&gt; template.</li>
<li><a href="http://www.cplusplus.com/reference/map/map/">c++map</a> - C++ STL map&lt;&gt; template.</li>
<li><a href="https://sites.google.com/site/binarysearchcube/">tesseract</a> - Binary Search Tesseract by Gregorius van den Hoven.</li>
<li><a href="https://code.google.com/p/sparsehash/source/browse/trunk/experimental/libchash.c">googlelibchash</a> - LibCHash by Craig Silverstein at Google.</li>
<li><a href="https://github.com/fredrikwidlund/libdynamic">libdynamic</a> - Hash set by Fredrik Widlund.</li>
<li><a href="http://concurrencykit.org/">concurrencykit</a> - Non-blocking hash set by Samy Al Bahra.</li>
</ul>
<p>Note that <em>googlelibchash</em> and <em>concurrencykit</em> are not shown in the graphs because they present a lot of spikes. See the <a class="el" href="benchmark.html#notes">Notes</a> the end.</p>
<h2><a class="anchor" id="thebenchmark"></a>
The Benchmark</h2>
<p>The benchmark consists in storing a set of N pointers to objects and searching them using integer keys.</p>
<p>Compared to the case of mapping integers to integers, mapping pointers to objects means that the pointers are also dereferenced, to simulate the object access, resulting in additional cache misses. This gives an advantage to implementations that store information in the objects itself, as the additional cache misses are already implicit.</p>
<p>The test done are:</p>
<ul>
<li><b>Insert</b> Insert all the objects starting with an empty container.</li>
<li><b>Change</b> Find and remove one object and reinsert it with a different key, repeated for all the objects.</li>
<li><b>Hit</b> Find with success all the objects and dereference them.</li>
<li><b>Miss</b> Find with failure all the objects.</li>
<li><b>Remove</b> Remove all the objects and dereference them.</li>
</ul>
<p>The <em>Change</em>, <em>Hit</em> and <em>Miss</em> tests operate always with N objects in the containers. The <em>Insert</em> test starts with an empty container, and the <em>Remove</em> test ends with an empty container. The objects are always dereferenced, as we are supposing to use them. This happens even in the remove case, as we are supposing to deallocate them.</p>
<p>All the objects are preallocated in the heap, and the allocation and deallocation time is not included in the test.</p>
<p>The objects contain an integer <em>value</em> field used for consistency checks, an unused <em>payload</em> field of 16 bytes, and any other data required by the data structure.</p>
<p>The objects are identified and stored using integer and unique <em>keys</em>. The key domain used is <b>dense</b>, and it's defined by the set of N even numbers starting from 0x80000000 to 0x80000000+2*N.</p>
<p>The use of even numbers allows to have missing keys inside the domain for the <em>Miss</em> and <em>Change</em> test. In such tests it's used the key domain defined by the set of N odd numbers starting from 0x80000000+1 to 0x80000000+2*N+1. Note that using additional keys at the corners of the domain would have given an unfair advantage to tries and trees as they implicitly keep track of the maximum and minimum key value inserted.</p>
<p>The use of the 0x80000000 base, allow to test a key domain not necessarily starting at 0. Using a 0 base would have given an unfair advantage to some implementation handling it as a special case.</p>
<p>For all the hashtables the keys are hashed using the <a class="el" href="tommyhash_8h.html#aea9c8438064a941d13e6f5462b5bff71" title="Integer reversible hash function for 32 bits.">tommy_inthash_u32()</a> function that ensures an uniform distribution. This hash function is also reversible, meaning that no collision is going to be caused by hashing the keys. For tries and trees the keys are not hashed, and used directly.</p>
<p>The tests are repeated using keys in <em>Random</em> mode and in <em>Forward</em> mode. In the forward mode the key values are used in order from the lowest to the highest. In the random mode the key values are used in a completely random order. In the <em>Change</em> test in forward mode, each object is reinserted using the previous key incremented by 1. In random mode each object is reinserted using a completely different and uncorrelated key.</p>
<p>The forward order advantages tries and trees as they use the key directly and they have a cache advantage on using consecutive keys. The random order advantages hashtables, as the hash function already randomizes the key. Usually real uses case are in between, and the random one is the worst case.</p>
<h2><a class="anchor" id="result"></a>
Results</h2>
<p>The most significant tests depend on your data usage model, but if in doubt, you can look at <em>Random Hit</em> and <em>Random Change</em>. They represent the real world worst condition.</p>
<div align="center">
<img src="def/img_random_hit.png" alt="img_random_hit.png"/>
</div>
<p>In the <em>Random Hit</em> graph you can see a vertical split at the 100.000 elements limit. Before this limit the cache of modern processor is able to contains most of the data, and it allows a very fast access with almost all data structures. After this limit, the number of cache misses is the dominant factor, and the curve depends mainly on the number of cache-miss required.</p>
<p>rbtree and nedtrie grow as log2(N) as they have two branches on each node, <a class="el" href="tommytrieinp_8h.html#aa375bb131f3d221a24774aef08b27a0a" title="Trie container type.">tommy_trie_inplace</a> grows as log4(N), <a class="el" href="tommytrie_8h.html#a05c17b0ace098768808aa9effcaa9559" title="Trie container type.">tommy_trie</a> as log8(N) and hashtables are almost constant and don't grow. For <a class="el" href="tommytrieinp_8h.html#aa375bb131f3d221a24774aef08b27a0a" title="Trie container type.">tommy_trie_inplace</a> and <a class="el" href="tommytrie_8h.html#a05c17b0ace098768808aa9effcaa9559" title="Trie container type.">tommy_trie</a> you can change the grow curve configuring a different number of branches for node.</p>
<div align="center">
<img src="def/img_random_change.png" alt="img_random_change.png"/>
</div>
<p>The <em>Random Change</em> graph confirms the vertical split at the 100.000 elements limit. It also show that hashtables are almost unbeatable with a random access.</p>
<h2><a class="anchor" id="random"></a>
Random order</h2>
<p>Here you can see the whole <em>Random</em> test results in different platforms.</p>
<p>In the <em>Random</em> test, hashtables are almost always winning, seconds are tries, and as last trees.</p>
<p>The best choices are <a class="el" href="tommyhashdyn_8h.html#a00c8b944d273f38f9eef91417a1e8991" title="Hashtable container type.">tommy_hashdyn</a>, <a class="el" href="tommyhashlin_8h.html#ad910f88af8bcd013a8e3cd30d528b904" title="Hashtable container type.">tommy_hashlin</a>, and googledensehash, with <a class="el" href="tommyhashlin_8h.html#ad910f88af8bcd013a8e3cd30d528b904" title="Hashtable container type.">tommy_hashlin</a> having the advantage to be real-time friendly and not increasing the heap fragmentation. </p>
<table  border="0">
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_random_insert.png" alt="img_random_insert.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_random_hit.png" alt="img_random_hit.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_random_miss.png" alt="img_random_miss.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_random_change.png" alt="img_random_change.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_random_remove.png" alt="img_random_remove.png"/>
</div>
  </td></tr>
</table>
<h2><a class="anchor" id="forward"></a>
Forward order</h2>
<p>Here you can see the whole <em>Forward</em> test results in different platforms.</p>
<p>In the <em>Forward</em> test, tries are the winners. Hashtables are competitive until the cache limit, then they lose against tries. Trees are the slowest.</p>
<p>The best choices are <a class="el" href="tommytrie_8h.html#a05c17b0ace098768808aa9effcaa9559" title="Trie container type.">tommy_trie</a> and <a class="el" href="tommytrieinp_8h.html#aa375bb131f3d221a24774aef08b27a0a" title="Trie container type.">tommy_trie_inplace</a>, where <a class="el" href="tommytrie_8h.html#a05c17b0ace098768808aa9effcaa9559" title="Trie container type.">tommy_trie</a> is a bit faster, and <a class="el" href="tommytrieinp_8h.html#aa375bb131f3d221a24774aef08b27a0a" title="Trie container type.">tommy_trie_inplace</a> doesn't require a custom allocator.</p>
<p>Note that also hashtables are faster in forward order than random. This may seem a bit surprising as the hash function randomizes the access even with consecutive keys. This happens because the objects are allocated in consecutive memory, and accessing them in order, improves the cache utilization, even if the hashed key is random.</p>
<p>Note that you can make hashtables to reach tries performance tweaking the hash function to put near keys allocated nearby. This is possible if you know in advance the distribution of keys. For example, in the benchmark you could use something like: </p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #define hash(v) tommy_inthash_u32(v &amp; ~0xF) + (v &amp; 0xF)</span>
</pre></div><p> and make keys that differ only by the lowest bits to have hashes with the same property, resulting in objects stored nearby, and improving cache utilization.</p>
<table  border="0">
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_forward_insert.png" alt="img_forward_insert.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_forward_hit.png" alt="img_forward_hit.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_forward_miss.png" alt="img_forward_miss.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_forward_change.png" alt="img_forward_change.png"/>
</div>
 </td></tr>
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_forward_remove.png" alt="img_forward_remove.png"/>
</div>
  </td></tr>
</table>
<h2><a class="anchor" id="size"></a>
Size</h2>
<p>Here you can see the memory usage of the different data structures. </p>
<table  border="0">
<tr>
<td><div align="center">
<img src="core_i5_650_3G2_linux/img_random_size.png" alt="img_random_size.png"/>
</div>
  </td></tr>
</table>
<h2><a class="anchor" id="code"></a>
Code</h2>
<p>The compilers used in the benchmark are:</p>
<ul>
<li><b>gcc 4.9.2</b> in Linux with options: -O3 -march=nehalem</li>
<li><b>Visual C 2012</b> in Windows with options: /Ox /Oy- /GL /GS- /arch:SSE2</li>
</ul>
<p>The following is pseudo code of the benchmark used. In this case it's written for the C++ unordered_map.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #define N 10000000 // Number of elements</span>
<span class="preprocessor"></span><span class="preprocessor"> #define PAYLOAD 16 // Size of the object</span>
<span class="preprocessor"></span>
 <span class="comment">// Basic object inserted in the colletion</span>
 <span class="keyword">struct </span>obj {
     <span class="keywordtype">unsigned</span> value; <span class="comment">// Key used for searching</span>
     <span class="keywordtype">char</span> payload[PAYLOAD];
 };

 <span class="comment">// Custom hash function to avoid to use the STL one</span>
 <span class="keyword">class </span>custom_hash {
 <span class="keyword">public</span>:
     <span class="keywordtype">unsigned</span> operator()(<span class="keywordtype">unsigned</span> key)<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="tommyhash_8h.html#aea9c8438064a941d13e6f5462b5bff71" title="Integer reversible hash function for 32 bits.">tommy_inthash_u32</a>(key); }
 };

 <span class="comment">// Map collection from &quot;unsigned&quot; to &quot;pointer to object&quot;</span>
 <span class="keyword">typedef</span> std::unordered_map&lt;unsigned, obj*, custom_hash&gt; bag_t;
 bag_t bag;

 <span class="comment">// Preallocate objects</span>
 obj* OBJ = <span class="keyword">new</span> obj[N];

 <span class="comment">// Keys used for inserting and searching elements</span>
 <span class="keywordtype">unsigned</span> INSERT[N];
 <span class="keywordtype">unsigned</span> SEARCH[N];

 <span class="comment">// Initialize the keys</span>
 <span class="keywordflow">for</span>(i=0;i&lt;N;++i) {
     INSERT[i] = 0x80000000 + i * 2;
     SEARCH[i] = 0x80000000 + i * 2;
 }

 <span class="comment">// If random order is required, shuffle the keys with Fisher-Yates</span>
 <span class="comment">// The two key orders are not correlated</span>
 <span class="keywordflow">if</span> (test_random) {
     std::random_shuffle(INSERT, INSERT + N);
     std::random_shuffle(SEARCH, SEARCH + N);
 }
</pre></div><h3><a class="anchor" id="insertion"></a>
Insert benchmark</h3>
<div class="fragment"><pre class="fragment"> <span class="keywordflow">for</span>(i=0;i&lt;N;++i) {
     <span class="comment">// Setup the element to insert</span>
     <span class="keywordtype">unsigned</span> key = INSERT[i];
     obj* element = &amp;OBJ[i];
     element-&gt;value = key;

     <span class="comment">// Insert it</span>
     bag[key] = element;
 }
</pre></div><h3><a class="anchor" id="change"></a>
Change benchmark</h3>
<div class="fragment"><pre class="fragment"> <span class="keywordflow">for</span>(i=0;i&lt;N;++i) {
     <span class="comment">// Search the element</span>
     <span class="keywordtype">unsigned</span> key = SEARCH[i];
     bag_t::iterator j = bag.find(key);
     <span class="keywordflow">if</span> (j == bag.end())
         abort();

     <span class="comment">// Remove it</span>
     obj* element = j-&gt;second;
     bag.erase(j);

     <span class="comment">// Reinsert the element with a new key</span>
     <span class="comment">// Use +1 in the key to ensure that the new key is unique</span>
     key = INSERT[i] + 1;
     element-&gt;value = key;
     bag[key] = element;
 }
</pre></div><h3><a class="anchor" id="hit"></a>
Hit benchmark</h3>
<div class="fragment"><pre class="fragment"> <span class="keywordflow">for</span>(i=0;i&lt;N;++i) {
     <span class="comment">// Search the element</span>
     <span class="comment">// Use a different key order than insertion</span>
     <span class="comment">// Use +1 in the key because we run after the &quot;Change&quot; test</span>
     <span class="keywordtype">unsigned</span> key = SEARCH[i] + 1;
     bag_t::const_iterator j = bag.find(key);
     <span class="keywordflow">if</span> (j == bag.end())
         abort();

     <span class="comment">// Ensure that it&#39;s the correct element.</span>
     <span class="comment">// This operation is like using the object after finding it,</span>
     <span class="comment">// and likely involves a cache-miss operation.</span>
     obj* element = j-&gt;second;
     <span class="keywordflow">if</span> (element-&gt;value != key)
         abort();
 }
</pre></div><h3><a class="anchor" id="miss"></a>
Miss benchmark</h3>
<div class="fragment"><pre class="fragment"> <span class="keywordflow">for</span>(i=0;i&lt;N;++i) {
     <span class="comment">// Search the element</span>
     <span class="comment">// All the keys are now shifted by +1 by the &quot;Change&quot; test, and we&#39;ll find nothing</span>
     <span class="keywordtype">unsigned</span> key = SEARCH[i];
     bag_t::const_iterator j = bag.find(key);
     <span class="keywordflow">if</span> (j != bag.end())
         abort();
 }
</pre></div><h3><a class="anchor" id="remove"></a>
Remove benchmark</h3>
<div class="fragment"><pre class="fragment"> <span class="keywordflow">for</span>(i=0;i&lt;N;++i) {
     <span class="comment">// Search the element</span>
     <span class="comment">// Use +1 in the key because we run after the &quot;Change&quot; test</span>
     <span class="keywordtype">unsigned</span> key = SEARCH[i] + 1;
     bag_t::iterator j = bag.find(key);
     <span class="keywordflow">if</span> (j == bag.end())
         abort();

     <span class="comment">// Remove it</span>
     bag.erase(j);

     <span class="comment">// Ensure that it&#39;s the correct element.</span>
     obj* element = j-&gt;second;
     <span class="keywordflow">if</span> (element-&gt;value != key)
         abort();
 }
</pre></div><h2><a class="anchor" id="others"></a>
Other benchmarks</h2>
<p>Here some links to other performance comparison:</p>
<p><a href="http://attractivechaos.wordpress.com/2008/08/28/comparison-of-hash-table-libraries/">Comparison of Hash Table Libraries</a></p>
<p><a href="http://incise.org/hash-table-benchmarks.html">Hash Table Benchmarks</a></p>
<h2><a class="anchor" id="notes"></a>
Notes</h2>
<p>Here some notes about the data structure tested not part of Tommy.</p>
<h3><a class="anchor" id="googlelibchash"></a>
Google C libchash</h3>
<p>It's the C implementation located in the <em>experimental/</em> directory of the googlesparsehash archive. It has very bad performances in the <em>Change</em> test for some N values. See this <a href="other/googlelibchash_problem.png">graph</a> with a lot of spikes. The C++ version doesn't suffer of this problem.</p>
<h3><a class="anchor" id="googledensehash"></a>
Google C++ densehash</h3>
<p>It doesn't release memory on deletion. To avoid an unfair advantage in the <em>Remove</em> test, we force a periodic resize calling resize(0) after any deallocation. The resize is executed when the load factor is lower than 20%.</p>
<h3><a class="anchor" id="khash"></a>
khash</h3>
<p>It doesn't release memory on deletion. This gives an unfair advantage on the <em>Remove</em> test.</p>
<h3><a class="anchor" id="nedtrie"></a>
nedtrie</h3>
<p>I've found a crash bug when inserting keys with the 0 value. The <a href="https://github.com/ned14/nedtries/commit/21039696f27db4ffac70a82f89dc5d00ae74b332">fix</a> of this issue is now in the nedtries github. We do not use the C++ implementation as it doesn't compile with gcc 4.4.3.</p>
<h3><a class="anchor" id="judy"></a>
Judy</h3>
<p>Sometimes it has bad performances in some specific platform and for some specific input data size. This makes difficult to predict the performance, as it is usually good until you get one of these cases. See for example this <a href="other/judy_problem.png">graph</a> with a big replicable spike at 50.000 elements.</p>
<h3><a class="anchor" id="ck"></a>
Concurrency Kit</h3>
<p>It has very bad performances in the <em>Change</em> test for some N values. See this <a href="other/ck_problem.png">graph</a> with a lot of spikes. </p>
</div></div>
</body>
</html>
